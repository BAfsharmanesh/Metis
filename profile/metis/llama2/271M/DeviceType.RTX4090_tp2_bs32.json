{
  "model": {
    "model_name": "llama2_271M",
    "num_layers": 16,
    "parameters": {
      "total_parameters_bytes": 1084362752.0,
      "parameters_per_layer_bytes": [
        131072000,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        51388416.0,
        4096,
        131072000
      ],
      "activation_parameters_bytes": [
        268435456,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        4160749568.0,
        268435456,
        8388608000
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 1128.6250421814561,
    "forward_backward_time_ms": 1079.2153329751595,
    "batch_generator_time_ms": 35.48482137939366,
    "layernorm_grads_all_reduce_time_ms": null,
    "embedding_grads_all_reduce_time_ms": null,
    "optimizer_time_ms": 8.330029528435992,
    "layer_compute_total_ms": [
      7.050985691251219,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      60.577274797266384,
      1.625241056747151,
      69.74719970166127
    ]
  },
  "execution_memory": {
    "total_memory_mb": 69580.37559509277,
    "layer_memory_total_mb": [
      313.00000381469727,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      3043.5312995910645,
      256.14062881469727,
      506.00000381469727
    ]
  }
}