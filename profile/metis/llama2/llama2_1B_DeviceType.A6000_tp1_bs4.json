{
  "model": {
    "model_name": "llama2_1B",
    "num_layers": 18,
    "parameters": {
      "total_parameters_bytes": 4223967232.0,
      "parameters_per_layer_bytes": [
        262144000,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        8192,
        262144000
      ],
      "activation_parameters_bytes": [
        67108864,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        1040187392.0,
        67108864,
        1048576000
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 3055.1945259943104,
    "forward_backward_time_ms": 2877.6450327464513,
    "batch_generator_time_ms": 20.25846072605678,
    "layernorm_grads_all_reduce_time_ms": null,
    "embedding_grads_all_reduce_time_ms": null,
    "optimizer_time_ms": 146.72459357439743,
    "layer_compute_total_ms": [
      0.27860913957868305,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      150.53804431642806,
      3.015858786446708,
      144.64047976902552
    ]
  },
  "execution_memory": {
    "total_memory_mb": 42922.2506942749,
    "layer_memory_total_mb": [
      1000.0625038146973,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      2128.8750495910645,
      128.06250381469727,
      1064.0000038146973
    ]
  }
}