{
  "model": {
    "model_name": "llama2_1B",
    "num_layers": 18,
    "parameters": {
      "total_parameters_bytes": 4223967232.0,
      "parameters_per_layer_bytes": [
        262144000,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        8192,
        262144000
      ],
      "activation_parameters_bytes": [
        134217728,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        2080374784.0,
        134217728,
        2097152000
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 589.8725709263522,
    "forward_backward_time_ms": 562.1299817704345,
    "batch_generator_time_ms": 9.931884245358791,
    "layernorm_grads_all_reduce_time_ms": null,
    "embedding_grads_all_reduce_time_ms": null,
    "optimizer_time_ms": 12.482345414795297,
    "layer_compute_total_ms": [
      2.884656635528974,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      29.527310306954995,
      0.7931051698615532,
      17.33467968741171
    ]
  },
  "execution_memory": {
    "total_memory_mb": 22080.313194274902,
    "layer_memory_total_mb": [
      437.62500381469727,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      1060.5937995910645,
      64.04687881469727,
      378.00000381469727
    ]
  }
}