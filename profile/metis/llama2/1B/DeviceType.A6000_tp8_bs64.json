{
  "model": {
    "model_name": "llama2_1B",
    "num_layers": 18,
    "parameters": {
      "total_parameters_bytes": 4223967232.0,
      "parameters_per_layer_bytes": [
        262144000,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        205537280.0,
        8192,
        262144000
      ],
      "activation_parameters_bytes": [
        1073741824,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        16642998272.0,
        1073741824,
        16777216000
      ]
    }
  },
  "execution_time": {
    "total_time_ms": 16664.059068800587,
    "forward_backward_time_ms": 16274.639010429382,
    "batch_generator_time_ms": 324.5662961687361,
    "layernorm_grads_all_reduce_time_ms": null,
    "embedding_grads_all_reduce_time_ms": null,
    "optimizer_time_ms": 42.16952867324124,
    "layer_compute_total_ms": [
      76.14357130868095,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      868.3387466839381,
      6.288664681570871,
      292.85131181989397
    ]
  },
  "execution_memory": {
    "total_memory_mb": 759857.0055541992,
    "layer_memory_total_mb": [
      2758.000030517578,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      36635.500396728516,
      2048.750030517578,
      9192.000030517578
    ]
  }
}